{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "523edd27-7403-4bbf-af87-5cff6359f324",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import os\n",
    "from ocr_model import OCRModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e71e2ade-97c5-457d-b74f-6733bdb7d225",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CaptchaDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, img_width=200, img_height=50, transform=None,\n",
    "                 char_to_idx=None, idx_to_char=None):\n",
    "        self.image_paths = image_paths\n",
    "        # Filter out non-alphanumeric characters from labels\n",
    "        self.labels = [''.join(char for char in label if char.isalnum()) for label in labels]\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.transform = transform\n",
    "        \n",
    "        if char_to_idx is None or idx_to_char is None:\n",
    "            # Create character mappings if not provided\n",
    "            self.characters = sorted(list(set(char for label in self.labels for char in label)))\n",
    "            self.char_to_idx = {char: idx + 1 for idx, char in enumerate(self.characters)}\n",
    "            self.idx_to_char = {idx + 1: char for idx, char in enumerate(self.characters)}\n",
    "            self.idx_to_char[0] = ''\n",
    "        else:\n",
    "            self.char_to_idx = char_to_idx\n",
    "            self.idx_to_char = idx_to_char\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        label_indices = [self.char_to_idx[char] for char in label]\n",
    "        return {\n",
    "            'image': image,\n",
    "            'label': torch.tensor(label_indices, dtype=torch.long),\n",
    "            'label_length': torch.tensor(len(label_indices), dtype=torch.long),\n",
    "            'text': label\n",
    "        }\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"Custom collate function to handle variable length sequences\"\"\"\n",
    "    batch.sort(key=lambda x: len(x['label']), reverse=True)\n",
    "    max_length = len(batch[0]['label'])\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    label_lengths = []\n",
    "    texts = []\n",
    "    \n",
    "    for item in batch:\n",
    "        images.append(item['image'])\n",
    "        curr_label = item['label']\n",
    "        curr_len = len(curr_label)\n",
    "        if curr_len < max_length:\n",
    "            padding = torch.zeros(max_length - curr_len, dtype=torch.long)\n",
    "            curr_label = torch.cat([curr_label, padding])\n",
    "        labels.append(curr_label)\n",
    "        label_lengths.append(item['label_length'])\n",
    "        texts.append(item['text'])\n",
    "    \n",
    "    images = torch.stack(images)\n",
    "    labels = torch.stack(labels)\n",
    "    label_lengths = torch.stack(label_lengths)\n",
    "    \n",
    "    return {\n",
    "        'image': images,\n",
    "        'label': labels,\n",
    "        'label_length': label_lengths,\n",
    "        'text': texts\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def decode_predictions(log_probs, idx_to_char):\n",
    "    \"\"\"Decode CTC output to text\"\"\"\n",
    "    pred_indices = torch.argmax(log_probs, dim=2)\n",
    "    batch_texts = []\n",
    "\n",
    "    for pred in pred_indices:\n",
    "        text = []\n",
    "        for i in range(len(pred)):\n",
    "            if i == 0 or pred[i] != pred[i-1]:\n",
    "                if pred[i] != 0:  # 0 is CTC blank\n",
    "                    text.append(idx_to_char[pred[i].item()])\n",
    "        batch_texts.append(''.join(text))\n",
    "\n",
    "    return batch_texts\n",
    "\n",
    "def evaluate_model(model, val_loader, idx_to_char, device):\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    char_correct = 0\n",
    "    total_chars = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images = batch['image'].to(device)\n",
    "            targets = batch['text']  # Original text labels\n",
    "            \n",
    "            # Get model predictions\n",
    "            log_probs = model(images)\n",
    "            predictions = decode_predictions(log_probs, idx_to_char)\n",
    "            \n",
    "            # Store predictions and targets\n",
    "            all_predictions.extend(predictions)\n",
    "            all_targets.extend(targets)\n",
    "            \n",
    "            # Calculate per-character accuracy\n",
    "            for pred, target in zip(predictions, targets):\n",
    "                # Pad shorter string with spaces to match lengths\n",
    "                max_len = max(len(pred), len(target))\n",
    "                pred = pred.ljust(max_len)\n",
    "                target = target.ljust(max_len)\n",
    "                \n",
    "                # Count correct characters\n",
    "                char_correct += sum(p == t for p, t in zip(pred, target))\n",
    "                total_chars += max_len\n",
    "\n",
    "    # Calculate sequence-level metrics\n",
    "    correct_sequences = sum(p == t for p, t in zip(all_predictions, all_targets))\n",
    "    total_sequences = len(all_predictions)\n",
    "    sequence_accuracy = correct_sequences / total_sequences\n",
    "\n",
    "    # Calculate character-level accuracy\n",
    "    char_accuracy = char_correct / total_chars if total_chars > 0 else 0\n",
    "\n",
    "    # Calculate character-level precision, recall, and F1 score\n",
    "    char_tp = 0  # True positives\n",
    "    char_fp = 0  # False positives\n",
    "    char_fn = 0  # False negatives\n",
    "    \n",
    "    for pred, target in zip(all_predictions, all_targets):\n",
    "        # Create sets of (char, position) tuples for both prediction and target\n",
    "        pred_chars = set((c, i) for i, c in enumerate(pred))\n",
    "        target_chars = set((c, i) for i, c in enumerate(target))\n",
    "        \n",
    "        # Calculate metrics\n",
    "        char_tp += len(pred_chars & target_chars)\n",
    "        char_fp += len(pred_chars - target_chars)\n",
    "        char_fn += len(target_chars - pred_chars)\n",
    "    \n",
    "    # Calculate precision, recall, and F1\n",
    "    precision = char_tp / (char_tp + char_fp) if (char_tp + char_fp) > 0 else 0\n",
    "    recall = char_tp / (char_tp + char_fn) if (char_tp + char_fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        'sequence_accuracy': sequence_accuracy,\n",
    "        'char_accuracy': char_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "# Define character set\n",
    "characters = (\n",
    "    [str(i) for i in range(10)] +  # 0-9\n",
    "    [chr(i) for i in range(65, 91)] +  # A-Z\n",
    "    [chr(i) for i in range(97, 123)]   # a-z\n",
    ")\n",
    "characters = sorted(characters)\n",
    "\n",
    "# Create character mappings\n",
    "char_to_idx = {char: idx + 1 for idx, char in enumerate(characters)}\n",
    "idx_to_char = {idx + 1: char for idx, char in enumerate(characters)}\n",
    "idx_to_char[0] = ''  # Add blank token\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7263db39-d821-4d35-9ea7-7628f8886cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Found 769 validation images\n",
      "\n",
      "Model Evaluation Results:\n",
      "Sequence Accuracy: 0.9350\n",
      "Character Accuracy: 0.9794\n",
      "Character Precision: 0.9816\n",
      "Character Recall: 0.9801\n",
      "Character F1 Score: 0.9808\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the model\n",
    "model = OCRModel()\n",
    "model.load_state_dict(torch.load('best_model.pth', map_location=device))\n",
    "model = model.to(device)\n",
    "\n",
    "# Set up data transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((50, 200)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load validation data\n",
    "val_dir = \"./datasets/validation\"\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for ext in ['*.png', '*.jpg']:\n",
    "    for img_path in Path(val_dir).glob(ext):\n",
    "        image_paths.append(str(img_path))\n",
    "        label = img_path.stem.split('.')[0]\n",
    "        labels.append(label)\n",
    "\n",
    "print(f\"Found {len(image_paths)} validation images\")\n",
    "\n",
    "# Create validation dataset and loader\n",
    "val_dataset = CaptchaDataset(\n",
    "    image_paths,\n",
    "    labels,\n",
    "    transform=transform,\n",
    "    char_to_idx=char_to_idx,\n",
    "    idx_to_char=idx_to_char\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    collate_fn=custom_collate_fn\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "metrics = evaluate_model(model, val_loader, idx_to_char, device)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "print(f\"Sequence Accuracy: {metrics['sequence_accuracy']:.4f}\")\n",
    "print(f\"Character Accuracy: {metrics['char_accuracy']:.4f}\")\n",
    "print(f\"Character Precision: {metrics['precision']:.4f}\")\n",
    "print(f\"Character Recall: {metrics['recall']:.4f}\")\n",
    "print(f\"Character F1 Score: {metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64e2423-d9e1-49de-8f71-f12bf65c7902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12497615-d350-4e8d-8333-2ceb2382bad0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980391b6-4b72-4653-a37a-baa124aeb12c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b97d4c3-e604-4d43-8700-de29f9331664",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
